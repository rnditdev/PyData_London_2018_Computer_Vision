{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_Transfer Learning For classification.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"ngYvg6JLDUgP","colab_type":"text"},"cell_type":"markdown","source":["##  Applying knowledge to other fields: Transfer learning\n","Transfer learning is a very convenient technique consisting in using a previously trained model, reusing the weights adjusted for a benchmark (in the case of image classification problems it is Imagenet), \n","In this section we will gather images from two different flower types, coming from the flower17 dataset. \n","It is a 17 category flower dataset with 80 images for each class. The flowers chosen are some common flowers in the UK. The images have large scale, pose and light variations and there are also classes with large varations of images within the class and close similarity to other classes.\n","In this case we will gather the first 2 classes (Daffodil and Coltsfoot), and build a classifier on top of the pretrained VGG16 network.\n","\n","Previously, we will will do image data aughmentation, because the images quantity could be not enough to abstract all the elements of any species.\n","Let's start by importing all the needed libraries, including applications, preprocession, the checkpoint model and associated object, to allow saving the intermediate steps, and the cv2 and Numpy ones, for image processing and numerical base operation."]},{"metadata":{"id":"4YAsHjAYDUgW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"7913bd35-017c-4238-d4e0-e0d2f43b2ad0","executionInfo":{"status":"ok","timestamp":1524741632355,"user_tz":180,"elapsed":2865,"user":{"displayName":"Rodolfo Bonnin","photoUrl":"//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg","userId":"106064727165962483576"}}},"cell_type":"code","source":["from keras import applications\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras.models import Sequential, Model \n","from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n","from keras import backend as k \n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n","from keras.models import load_model\n","from keras.applications.vgg16 import VGG16, decode_predictions,preprocess_input\n","import cv2\n","from io import BytesIO\n","import numpy as np\n","import urllib\n","from PIL import Image"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"LLc87yXYDUg1","colab_type":"text"},"cell_type":"markdown","source":["In this section we will define all the variables affectin the input, data sources, and training parameters."]},{"metadata":{"id":"_60pIoLuDUg3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["img_width, img_height = 224, 224\n","train_data_dir = \"train\"\n","validation_data_dir = \"validation\"\n","nb_train_samples = 300\n","nb_validation_samples = 100 \n","batch_size = 16\n","epochs = 20"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z7u8uKThDUhD","colab_type":"text"},"cell_type":"markdown","source":["Now we will invoke the VGG16 pretrained model, not including the top flattening layers."]},{"metadata":{"id":"Fh1i6tccDUhG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":110},"outputId":"472a34c2-d9e9-47fe-85b8-53247d74c283","executionInfo":{"status":"ok","timestamp":1524741636906,"user_tz":180,"elapsed":3079,"user":{"displayName":"Rodolfo Bonnin","photoUrl":"//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg","userId":"106064727165962483576"}}},"cell_type":"code","source":["model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n","\n","# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n","for layer in model.layers[:5]:\n","    layer.trainable = False\n","\n","#Adding custom Layers \n","x = model.output\n","x = Flatten()(x)\n","x = Dense(1024, activation=\"relu\")(x)\n","x = Dropout(0.5)(x)\n","x = Dense(1024, activation=\"relu\")(x)\n","predictions = Dense(2, activation=\"softmax\")(x)\n","\n","# creating the final model \n","model_final = Model(input = model.input, output = predictions)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  app.launch_new_instance()\n"],"name":"stderr"}]},{"metadata":{"id":"VJ6E9Vn7DUhU","colab_type":"text"},"cell_type":"markdown","source":["Now its time to compile the model, and create the  image data authmentation object for the training and testing dataset"]},{"metadata":{"id":"YdKffqFxPqEM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":217},"outputId":"fa929c2c-32b1-4526-c617-a3377fa13692","executionInfo":{"status":"ok","timestamp":1524741640101,"user_tz":180,"elapsed":2952,"user":{"displayName":"Rodolfo Bonnin","photoUrl":"//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg","userId":"106064727165962483576"}}},"cell_type":"code","source":["!wget https://s3.amazonaws.com/italia18/transfer_learning_dataset.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2018-04-26 10:23:43--  https://s3.amazonaws.com/italia18/transfer_learning_dataset.zip\r\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.33.186\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.33.186|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7848999 (7.5M) [application/zip]\n","Saving to: ‘transfer_learning_dataset.zip’\n","\n","transfer_learning_d 100%[===================>]   7.49M  5.89MB/s    in 1.3s    \n","\n","2018-04-26 10:23:45 (5.89 MB/s) - ‘transfer_learning_dataset.zip’ saved [7848999/7848999]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"pUEOhp8YxSw_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3217},"outputId":"d77ad6bc-f01d-4abd-86ae-c34ddfa413fc","executionInfo":{"status":"ok","timestamp":1524741712726,"user_tz":180,"elapsed":1573,"user":{"displayName":"Rodolfo Bonnin","photoUrl":"//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg","userId":"106064727165962483576"}}},"cell_type":"code","source":["!unzip -o transfer_learning_dataset.zip"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Archive:  transfer_learning_dataset.zip\r\n","   creating: test/\r\n","  inflating: test/butt2.jpg          \r\n","  inflating: test/butter1.jpg        \r\n","  inflating: test/coldsfoot.jpg      \r\n","  inflating: test/coltsfoot-flower.jpg  \r\n","  inflating: test/daff1.jpg          \r\n","  inflating: test/gaff2.jpg          \r\n","  inflating: test/galan.jpg          \r\n","  inflating: test/galant2.jpg        \r\n","   creating: train/\r\n","   creating: train/1/\r\n","  inflating: train/1/image_0001.jpg  \r\n","  inflating: train/1/image_0002.jpg  \r\n","  inflating: train/1/image_0003.jpg  \r\n","  inflating: train/1/image_0004.jpg  \r\n","  inflating: train/1/image_0005.jpg  \r\n","  inflating: train/1/image_0006.jpg  \r\n","  inflating: train/1/image_0007.jpg  \r\n","  inflating: train/1/image_0008.jpg  \r\n","  inflating: train/1/image_0009.jpg  \r\n","  inflating: train/1/image_0010.jpg  \r\n","  inflating: train/1/image_0011.jpg  \r\n","  inflating: train/1/image_0012.jpg  \r\n","  inflating: train/1/image_0013.jpg  \r\n","  inflating: train/1/image_0014.jpg  \r\n","  inflating: train/1/image_0015.jpg  \r\n","  inflating: train/1/image_0016.jpg  \r\n","  inflating: train/1/image_0017.jpg  \r\n","  inflating: train/1/image_0018.jpg  \r\n","  inflating: train/1/image_0019.jpg  \r\n","  inflating: train/1/image_0020.jpg  \r\n","  inflating: train/1/image_0021.jpg  \r\n","  inflating: train/1/image_0022.jpg  \r\n","  inflating: train/1/image_0023.jpg  \r\n","  inflating: train/1/image_0024.jpg  \r\n","  inflating: train/1/image_0025.jpg  \r\n","  inflating: train/1/image_0026.jpg  \r\n","  inflating: train/1/image_0027.jpg  \r\n","  inflating: train/1/image_0028.jpg  \r\n","  inflating: train/1/image_0029.jpg  \r\n","  inflating: train/1/image_0030.jpg  \r\n","  inflating: train/1/image_0031.jpg  \r\n","  inflating: train/1/image_0032.jpg  \r\n","  inflating: train/1/image_0033.jpg  \r\n","  inflating: train/1/image_0034.jpg  \r\n","  inflating: train/1/image_0035.jpg  \r\n","  inflating: train/1/image_0036.jpg  \r\n","  inflating: train/1/image_0037.jpg  \r\n","  inflating: train/1/image_0038.jpg  \r\n","  inflating: train/1/image_0039.jpg  \r\n","  inflating: train/1/image_0040.jpg  \r\n","  inflating: train/1/image_0041.jpg  \r\n","  inflating: train/1/image_0042.jpg  \r\n","  inflating: train/1/image_0043.jpg  \r\n","  inflating: train/1/image_0044.jpg  \r\n","  inflating: train/1/image_0045.jpg  \r\n","  inflating: train/1/image_0046.jpg  \r\n","  inflating: train/1/image_0047.jpg  \r\n","  inflating: train/1/image_0048.jpg  \r\n","  inflating: train/1/image_0049.jpg  \r\n","  inflating: train/1/image_0050.jpg  \r\n","  inflating: train/1/image_0051.jpg  \r\n","  inflating: train/1/image_0052.jpg  \r\n","  inflating: train/1/image_0053.jpg  \r\n","  inflating: train/1/image_0054.jpg  \r\n","  inflating: train/1/image_0055.jpg  \r\n","  inflating: train/1/image_0056.jpg  \r\n","  inflating: train/1/image_0057.jpg  \r\n","  inflating: train/1/image_0058.jpg  \r\n","  inflating: train/1/image_0059.jpg  \r\n","  inflating: train/1/image_0060.jpg  \r\n","   creating: train/2/\r\n","  inflating: train/2/image_0081.jpg  \r\n","  inflating: train/2/image_0082.jpg  \r\n","  inflating: train/2/image_0083.jpg  \r\n","  inflating: train/2/image_0084.jpg  \r\n","  inflating: train/2/image_0085.jpg  \r\n","  inflating: train/2/image_0086.jpg  \n","  inflating: train/2/image_0087.jpg  \n","  inflating: train/2/image_0088.jpg  \n","  inflating: train/2/image_0089.jpg  \n","  inflating: train/2/image_0090.jpg  \n","  inflating: train/2/image_0091.jpg  \n","  inflating: train/2/image_0092.jpg  \n","  inflating: train/2/image_0093.jpg  \n","  inflating: train/2/image_0094.jpg  \n","  inflating: train/2/image_0095.jpg  \n","  inflating: train/2/image_0096.jpg  \n","  inflating: train/2/image_0097.jpg  \n","  inflating: train/2/image_0098.jpg  \n","  inflating: train/2/image_0099.jpg  \n","  inflating: train/2/image_0100.jpg  \n","  inflating: train/2/image_0101.jpg  \n","  inflating: train/2/image_0102.jpg  \n","  inflating: train/2/image_0103.jpg  \n","  inflating: train/2/image_0104.jpg  \n","  inflating: train/2/image_0105.jpg  \n","  inflating: train/2/image_0106.jpg  \n","  inflating: train/2/image_0107.jpg  \n","  inflating: train/2/image_0108.jpg  \n","  inflating: train/2/image_0109.jpg  \n","  inflating: train/2/image_0110.jpg  \n","  inflating: train/2/image_0111.jpg  \n","  inflating: train/2/image_0112.jpg  \n","  inflating: train/2/image_0113.jpg  \n","  inflating: train/2/image_0114.jpg  \n","  inflating: train/2/image_0115.jpg  \n","  inflating: train/2/image_0116.jpg  \n","  inflating: train/2/image_0117.jpg  \n","  inflating: train/2/image_0118.jpg  \n","  inflating: train/2/image_0119.jpg  \n","  inflating: train/2/image_0120.jpg  \n","  inflating: train/2/image_0121.jpg  \n","  inflating: train/2/image_0122.jpg  \n","  inflating: train/2/image_0123.jpg  \n","  inflating: train/2/image_0124.jpg  \n","  inflating: train/2/image_0125.jpg  \n","  inflating: train/2/image_0126.jpg  \n","  inflating: train/2/image_0127.jpg  \n","  inflating: train/2/image_0128.jpg  \n","  inflating: train/2/image_0129.jpg  \n","  inflating: train/2/image_0130.jpg  \n","  inflating: train/2/image_0131.jpg  \n","  inflating: train/2/image_0132.jpg  \n","  inflating: train/2/image_0133.jpg  \n","  inflating: train/2/image_0134.jpg  \n","  inflating: train/2/image_0135.jpg  \n","  inflating: train/2/image_0136.jpg  \n","  inflating: train/2/image_0137.jpg  \n","  inflating: train/2/image_0138.jpg  \n","  inflating: train/2/image_0139.jpg  \n","  inflating: train/2/image_0140.jpg  \n","   creating: validation/\n","   creating: validation/1/\n","  inflating: validation/1/image_0061.jpg  \n","  inflating: validation/1/image_0062.jpg  \n","  inflating: validation/1/image_0063.jpg  \n","  inflating: validation/1/image_0064.jpg  \n","  inflating: validation/1/image_0065.jpg  \n","  inflating: validation/1/image_0066.jpg  \n","  inflating: validation/1/image_0067.jpg  \n","  inflating: validation/1/image_0068.jpg  \n","  inflating: validation/1/image_0069.jpg  \n","  inflating: validation/1/image_0070.jpg  \n","  inflating: validation/1/image_0071.jpg  \n","  inflating: validation/1/image_0072.jpg  \n","  inflating: validation/1/image_0073.jpg  \n","  inflating: validation/1/image_0074.jpg  \n","  inflating: validation/1/image_0075.jpg  \n","  inflating: validation/1/image_0076.jpg  \n","  inflating: validation/1/image_0077.jpg  \n","  inflating: validation/1/image_0078.jpg  \n","  inflating: validation/1/image_0079.jpg  \n","  inflating: validation/1/image_0080.jpg  \n","   creating: validation/2/\n","  inflating: validation/2/image_0141.jpg  \n","  inflating: validation/2/image_0142.jpg  \n","  inflating: validation/2/image_0143.jpg  \n","  inflating: validation/2/image_0144.jpg  \n","  inflating: validation/2/image_0145.jpg  \n","  inflating: validation/2/image_0146.jpg  \n","  inflating: validation/2/image_0147.jpg  \n","  inflating: validation/2/image_0148.jpg  \n","  inflating: validation/2/image_0149.jpg  \n","  inflating: validation/2/image_0150.jpg  \n","  inflating: validation/2/image_0151.jpg  \n","  inflating: validation/2/image_0152.jpg  \n","  inflating: validation/2/image_0153.jpg  \n","  inflating: validation/2/image_0154.jpg  \n","  inflating: validation/2/image_0155.jpg  \n","  inflating: validation/2/image_0156.jpg  \n","  inflating: validation/2/image_0157.jpg  \n","  inflating: validation/2/image_0158.jpg  \n","  inflating: validation/2/image_0159.jpg  \n","  inflating: validation/2/image_0160.jpg  \n"],"name":"stdout"}]},{"metadata":{"id":"qCMx0B4rDUhY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# compile the model \n","model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n","\n","# Initiate the train and test generators with data Augumentation \n","train_datagen = ImageDataGenerator(\n","rescale = 1./255,\n","horizontal_flip = True,\n","fill_mode = \"nearest\",\n","zoom_range = 0.3,\n","width_shift_range = 0.3,\n","height_shift_range=0.3,\n","rotation_range=30)\n","\n","test_datagen = ImageDataGenerator(\n","rescale = 1./255,\n","horizontal_flip = True,\n","fill_mode = \"nearest\",\n","zoom_range = 0.3,\n","width_shift_range = 0.3,\n","height_shift_range=0.3,\n","rotation_range=30)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3oCchbC8DUhg","colab_type":"text"},"cell_type":"markdown","source":["Now we will properly generate the new augmented data"]},{"metadata":{"id":"JE9iXT9bEHUs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3090},"outputId":"0547ed70-2bbd-4a16-8315-46480f62ceac","executionInfo":{"status":"ok","timestamp":1524741734358,"user_tz":180,"elapsed":2240,"user":{"displayName":"Rodolfo Bonnin","photoUrl":"//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg","userId":"106064727165962483576"}}},"cell_type":"code","source":["!unzip -o transfer_learning_dataset.zip"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Archive:  transfer_learning_dataset.zip\r\n","  inflating: test/butt2.jpg          \r\n","  inflating: test/butter1.jpg        \r\n","  inflating: test/coldsfoot.jpg      \r\n","  inflating: test/coltsfoot-flower.jpg  \r\n","  inflating: test/daff1.jpg          \r\n","  inflating: test/gaff2.jpg          \r\n","  inflating: test/galan.jpg          \r\n","  inflating: test/galant2.jpg        \r\n","  inflating: train/1/image_0001.jpg  \r\n","  inflating: train/1/image_0002.jpg  \r\n","  inflating: train/1/image_0003.jpg  \r\n","  inflating: train/1/image_0004.jpg  \r\n","  inflating: train/1/image_0005.jpg  \r\n","  inflating: train/1/image_0006.jpg  \r\n","  inflating: train/1/image_0007.jpg  \r\n","  inflating: train/1/image_0008.jpg  \r\n","  inflating: train/1/image_0009.jpg  \r\n","  inflating: train/1/image_0010.jpg  \r\n","  inflating: train/1/image_0011.jpg  \r\n","  inflating: train/1/image_0012.jpg  \r\n","  inflating: train/1/image_0013.jpg  \r\n","  inflating: train/1/image_0014.jpg  \r\n","  inflating: train/1/image_0015.jpg  \r\n","  inflating: train/1/image_0016.jpg  \r\n","  inflating: train/1/image_0017.jpg  \r\n","  inflating: train/1/image_0018.jpg  \r\n","  inflating: train/1/image_0019.jpg  \r\n","  inflating: train/1/image_0020.jpg  \r\n","  inflating: train/1/image_0021.jpg  \r\n","  inflating: train/1/image_0022.jpg  \r\n","  inflating: train/1/image_0023.jpg  \r\n","  inflating: train/1/image_0024.jpg  \r\n","  inflating: train/1/image_0025.jpg  \r\n","  inflating: train/1/image_0026.jpg  \r\n","  inflating: train/1/image_0027.jpg  \r\n","  inflating: train/1/image_0028.jpg  \r\n","  inflating: train/1/image_0029.jpg  \r\n","  inflating: train/1/image_0030.jpg  \r\n","  inflating: train/1/image_0031.jpg  \r\n","  inflating: train/1/image_0032.jpg  \r\n","  inflating: train/1/image_0033.jpg  \r\n","  inflating: train/1/image_0034.jpg  \r\n","  inflating: train/1/image_0035.jpg  \r\n","  inflating: train/1/image_0036.jpg  \r\n","  inflating: train/1/image_0037.jpg  \r\n","  inflating: train/1/image_0038.jpg  \r\n","  inflating: train/1/image_0039.jpg  \r\n","  inflating: train/1/image_0040.jpg  \r\n","  inflating: train/1/image_0041.jpg  \r\n","  inflating: train/1/image_0042.jpg  \r\n","  inflating: train/1/image_0043.jpg  \r\n","  inflating: train/1/image_0044.jpg  \r\n","  inflating: train/1/image_0045.jpg  \r\n","  inflating: train/1/image_0046.jpg  \r\n","  inflating: train/1/image_0047.jpg  \r\n","  inflating: train/1/image_0048.jpg  \r\n","  inflating: train/1/image_0049.jpg  \r\n","  inflating: train/1/image_0050.jpg  \r\n","  inflating: train/1/image_0051.jpg  \r\n","  inflating: train/1/image_0052.jpg  \r\n","  inflating: train/1/image_0053.jpg  \r\n","  inflating: train/1/image_0054.jpg  \r\n","  inflating: train/1/image_0055.jpg  \r\n","  inflating: train/1/image_0056.jpg  \r\n","  inflating: train/1/image_0057.jpg  \r\n","  inflating: train/1/image_0058.jpg  \r\n","  inflating: train/1/image_0059.jpg  \r\n","  inflating: train/1/image_0060.jpg  \r\n","  inflating: train/2/image_0081.jpg  \r\n","  inflating: train/2/image_0082.jpg  \r\n","  inflating: train/2/image_0083.jpg  \r\n","  inflating: train/2/image_0084.jpg  \r\n","  inflating: train/2/image_0085.jpg  \r\n","  inflating: train/2/image_0086.jpg  \r\n","  inflating: train/2/image_0087.jpg  \r\n","  inflating: train/2/image_0088.jpg  \n","  inflating: train/2/image_0089.jpg  \n","  inflating: train/2/image_0090.jpg  \n","  inflating: train/2/image_0091.jpg  \n","  inflating: train/2/image_0092.jpg  \n","  inflating: train/2/image_0093.jpg  \n","  inflating: train/2/image_0094.jpg  \n","  inflating: train/2/image_0095.jpg  \n","  inflating: train/2/image_0096.jpg  \n","  inflating: train/2/image_0097.jpg  \n","  inflating: train/2/image_0098.jpg  \n","  inflating: train/2/image_0099.jpg  \n","  inflating: train/2/image_0100.jpg  \n","  inflating: train/2/image_0101.jpg  \n","  inflating: train/2/image_0102.jpg  \n","  inflating: train/2/image_0103.jpg  \n","  inflating: train/2/image_0104.jpg  \n","  inflating: train/2/image_0105.jpg  \n","  inflating: train/2/image_0106.jpg  \n","  inflating: train/2/image_0107.jpg  \n","  inflating: train/2/image_0108.jpg  \n","  inflating: train/2/image_0109.jpg  \n","  inflating: train/2/image_0110.jpg  \n","  inflating: train/2/image_0111.jpg  \n","  inflating: train/2/image_0112.jpg  \n","  inflating: train/2/image_0113.jpg  \n","  inflating: train/2/image_0114.jpg  \n","  inflating: train/2/image_0115.jpg  \n","  inflating: train/2/image_0116.jpg  \n","  inflating: train/2/image_0117.jpg  \n","  inflating: train/2/image_0118.jpg  \n","  inflating: train/2/image_0119.jpg  \n","  inflating: train/2/image_0120.jpg  \n","  inflating: train/2/image_0121.jpg  \n","  inflating: train/2/image_0122.jpg  \n","  inflating: train/2/image_0123.jpg  \n","  inflating: train/2/image_0124.jpg  \n","  inflating: train/2/image_0125.jpg  \n","  inflating: train/2/image_0126.jpg  \n","  inflating: train/2/image_0127.jpg  \n","  inflating: train/2/image_0128.jpg  \n","  inflating: train/2/image_0129.jpg  \n","  inflating: train/2/image_0130.jpg  \n","  inflating: train/2/image_0131.jpg  \n","  inflating: train/2/image_0132.jpg  \n","  inflating: train/2/image_0133.jpg  \n","  inflating: train/2/image_0134.jpg  \n","  inflating: train/2/image_0135.jpg  \n","  inflating: train/2/image_0136.jpg  \n","  inflating: train/2/image_0137.jpg  \n","  inflating: train/2/image_0138.jpg  \n","  inflating: train/2/image_0139.jpg  \n","  inflating: train/2/image_0140.jpg  \n","  inflating: validation/1/image_0061.jpg  \n","  inflating: validation/1/image_0062.jpg  \n","  inflating: validation/1/image_0063.jpg  \n","  inflating: validation/1/image_0064.jpg  \n","  inflating: validation/1/image_0065.jpg  \n","  inflating: validation/1/image_0066.jpg  \n","  inflating: validation/1/image_0067.jpg  \n","  inflating: validation/1/image_0068.jpg  \n","  inflating: validation/1/image_0069.jpg  \n","  inflating: validation/1/image_0070.jpg  \n","  inflating: validation/1/image_0071.jpg  \n","  inflating: validation/1/image_0072.jpg  \n","  inflating: validation/1/image_0073.jpg  \n","  inflating: validation/1/image_0074.jpg  \n","  inflating: validation/1/image_0075.jpg  \n","  inflating: validation/1/image_0076.jpg  \n","  inflating: validation/1/image_0077.jpg  \n","  inflating: validation/1/image_0078.jpg  \n","  inflating: validation/1/image_0079.jpg  \n","  inflating: validation/1/image_0080.jpg  \n","  inflating: validation/2/image_0141.jpg  \n","  inflating: validation/2/image_0142.jpg  \n","  inflating: validation/2/image_0143.jpg  \n","  inflating: validation/2/image_0144.jpg  \n","  inflating: validation/2/image_0145.jpg  \n","  inflating: validation/2/image_0146.jpg  \n","  inflating: validation/2/image_0147.jpg  \n","  inflating: validation/2/image_0148.jpg  \n","  inflating: validation/2/image_0149.jpg  \n","  inflating: validation/2/image_0150.jpg  \n","  inflating: validation/2/image_0151.jpg  \n","  inflating: validation/2/image_0152.jpg  \n","  inflating: validation/2/image_0153.jpg  \n","  inflating: validation/2/image_0154.jpg  \n","  inflating: validation/2/image_0155.jpg  \n","  inflating: validation/2/image_0156.jpg  \n","  inflating: validation/2/image_0157.jpg  \n","  inflating: validation/2/image_0158.jpg  \n","  inflating: validation/2/image_0159.jpg  \n","  inflating: validation/2/image_0160.jpg  \n"],"name":"stdout"}]},{"metadata":{"id":"QWP-sqbJDUhk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":53},"outputId":"5ccd0b17-0e74-480a-a8be-79a115f5e6ee","executionInfo":{"status":"ok","timestamp":1524741767782,"user_tz":180,"elapsed":1280,"user":{"displayName":"Rodolfo Bonnin","photoUrl":"//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg","userId":"106064727165962483576"}}},"cell_type":"code","source":["train_generator = train_datagen.flow_from_directory(\n","train_data_dir,\n","target_size = (img_height, img_width),\n","batch_size = batch_size, \n","class_mode = \"categorical\")\n","\n","validation_generator = test_datagen.flow_from_directory(\n","validation_data_dir,\n","target_size = (img_height, img_width),\n","class_mode = \"categorical\")\n","\n","# Save the model according to the conditions  \n","early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 120 images belonging to 2 classes.\n","Found 40 images belonging to 2 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"qAzuW65ODUht","colab_type":"text"},"cell_type":"markdown","source":["It's time to fit the new final layers for the model"]},{"metadata":{"id":"0SxfYqe3DUhv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":146},"outputId":"30441abd-952c-4e22-d580-b37fdf673305"},"cell_type":"code","source":["model_final.fit_generator(\n","train_generator,\n","samples_per_epoch = nb_train_samples,\n","nb_epoch = epochs,\n","validation_data = validation_generator,\n","nb_val_samples = nb_validation_samples,\n","callbacks = [early])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., callbacks=[<keras.ca..., steps_per_epoch=18, epochs=20, validation_steps=100)`\n","  import sys\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n"," 2/18 [==>...........................] - ETA: 6:56 - loss: 0.7705 - acc: 0.4375"],"name":"stdout"}]},{"metadata":{"id":"UZWGYOoLDUh5","colab_type":"text"},"cell_type":"markdown","source":["Then let's try with a daffoil image, testing the output of the classifier, which should output an array close to the [1.,0.] value, indicating that the probability for the first option is very high."]},{"metadata":{"id":"Y4QrOntYvpwW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title\n","im = cv2.resize(cv2.imread('test/gaff2.jpg'), (img_width, img_height))\n","im = np.expand_dims(im, axis=0).astype(np.float32)\n","im=preprocess_input(im)\n","print (im.shape)\n","out = model_final.predict(im)\n","model_classes=[\"Daffodil\",\"Coltsfoot\"]\n","print (model_classes[np.argmax(out)])\n","print (out)\n","print (\"Probability: \", out[0][np.argmax(out)])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lxQuQ8lnDUh7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def show_result(im):\n","  im = cv2.resize(im, (img_width, img_height))\n","  im = np.expand_dims(im, axis=0).astype(np.float32)\n","  im=preprocess_input(im)\n","  out = model_final.predict(im)\n","  model_classes=[\"Daffodil\",\"Coltsfoot\"]\n","  print (model_classes[np.argmax(out)])\n","  print (out)\n","  print (\"Probability: \", out[0][np.argmax(out)])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4QY1EqrGoU3E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":108},"outputId":"f7a2162e-5298-4598-8c3b-60a9f87ab10e","executionInfo":{"status":"ok","timestamp":1524222749849,"user_tz":180,"elapsed":953,"user":{"displayName":"Rodolfo Bonnin","photoUrl":"//lh4.googleusercontent.com/-WC0URIT6MsM/AAAAAAAAAAI/AAAAAAAAA_o/_XYb8BC-UBs/s50-c-k-no/photo.jpg","userId":"106064727165962483576"}}},"cell_type":"code","source":["#@Test your images\n","#@title Run on sample images {display-mode: \"form\"}\n","\n","SAMPLE_IMAGE = 'image1'  # @param ['image1', 'image2', 'image3']\n","IMAGE_URL = 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Coltsfoot.jpg/800px-Coltsfoot.jpg'  #@param {type:\"string\"}\n","\n","_SAMPLE_URL = ('https://github.com/tensorflow/models/blob/master/research/'\n","               'deeplab/g3doc/img/%s.jpg?raw=true')\n","\n","\n","def run_visualization(url):\n","  \"\"\"Running model on\"\"\"\n","  try:\n","    resp = urllib.request.urlopen(url)\n","    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n","    orignal_im = cv2.imdecode(image, cv2.IMREAD_COLOR)\n","\n","  except IOError:\n","    print('Cannot retrieve image. Please check url: ' + url)\n","    return\n","\n","  print('running model on image %s...' % url)\n","\n","\n","  show_result(orignal_im)\n","\n","\n","image_url = IMAGE_URL or _SAMPLE_URL % SAMPLE_IMAGE\n","run_visualization(image_url)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["running model on image https://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Coltsfoot.jpg/800px-Coltsfoot.jpg...\n","(1, 224, 224, 3)\n","Coltsfoot\n","[[0. 1.]]\n","Probability:  1.0\n"],"name":"stdout"}]}]}